---
title: "It's not fair: gerrymandering by whom?"
author: "Bruce Mallory"
date: "12/2/2020"
output: pdf_document
  
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load("HelpersMG", "readr", "ggplot2", "lmer4", "rstanarm", "dplyr", "stringr", "e1071", "ggrepel", "moderndive", "broom", "tidyr", "knitr", "pander", "kableExtra", "ggpubr")
options(dplyr.summarise.inform = FALSE)

#moderndive allows geom_parallel_slopes() ... see https://campus.datacamp.com/courses/intermediate-regression-in-r/parallel-slopes-1?ex=1
```
## ABSTRACT

## INTRODUCTION
Every ten years, after the census is completed, the 435 House Representatives are reapportioned among the states based on the current populations.  Then each state redraws its electoral districts, so the districts within a state have approximately equal populations.  Aside from mandating that the districts have equal populations, the Constitution is silent about the process and leaves the redrawing of districts to the states.  Redistricting laws in the different states vary as does the responsibility for redistricting.  In some states redistricting is done by the courts, in other states there are independent commissions.  And in the majority of states, redistricting is done by the state legislator and the governor.  Of these states, in 2011, twenty-three had a state legislature and a governor who belonged to the same political party.

In assessing the fairness of the redrawn electoral districts, there are four overlapping and often conflicting, perspectives.  

First is the hope that districts will be politically proportional, yet that doesn’t always happen.    In North Carolina, in 2018, the Democratic candidates (as a group) received 48.3% of the votes cast.  That year, only 3 of the 13 representatives (23%) were Democratic.  And in Massachusetts in 2018, Republican candidates received 36% of the votes cast, yet none of the 9 congressional representatives were Republican.

A second concern in redistricting is the competitiveness of the districts.  Clearly there is a relationship between the number of competitive districts and proportional-political-representation.  In the appendix I discuss my observations of the number of uncontested and competitive districts that I observed in the years that I’ve analyzed 2002 to 2018).

The third perspective about fairly drawn congressional districts is stipulated by the Voting Rights Act of 1965 and focuses on a minority groups’ ability to elect representatives of their choice.  The law addresses instances where this ability is diminished during redistricting and focuses on assuring that there are “majority-minority districts.”

And the fourth perspective on drawing “fair” electoral districts is most clearly articulated in California’s 2010 voter initiative that established a redistricting commission tasked with creating “communities of interest.”  The goal was to create districts that allow like-minded communities to have representation in congress.

The analysis that I am doing in this paper will only focus on proportional-political-representation and will not address minority representation or community representation.  All the while understanding that the Voting Rights Act impacts the drawing of districts in a manner that can skew proportional-political-representation (ironically, assuring majority-minority districts is a form of packing and can dilute Democratic representation).  And the goal of keeping communities of interest together can also impact proportional-political-representation.

In my current analysis, I will focus on the proportion of seats to votes.  Specifically, I define the proportional-political-representation coefficient (PPR) to be  the (% of seats) divided by the (% of votes).  From a proportional-political-representation perspective, if an election is “fair,” then the proportion of seat to votes should be 1.  And if you look at the seats and votes from one party’s perspective, if the proportion is greater than 1 then that party was advantaged.  As an example, in Massachusetts the representation proportion in 2018 was (100% seats) / (66% votes) = 1.52.  (In the appendix, I introduce another measure of political fairness called the “efficiency gap.”  As I continue to work on this paper, I will look at how the “efficiency gap” compares with the PPR outcome that I’m currently using.)

In my analysis, I am looking for differences in redistricting between those states that were controlled by Republicans, by Democrats, and by Others.

Who draws the districts can and often does have an impact on the political fairness of the districts.  There is no need for statistical analysis to convince you of this statement, nor do I need to argue the fact that gerrymandering is an aspect of politics.  But there are other factors aside from who drew the lines, that can impact the “fairness” of the resulting districts.

Gerrymandering writ-large, is accomplished by either “packing” (drawing district lines to pack one group into a small number of districts, which gives the other group an advantage in the remaining districts), or by “cracking” (drawing district lines to dilute one group’s votes by distributing those voters among numerous districts).

Though we know that those who are drawing political boundaries can pack a district, voters also pack districts when the choose where they will live.  And in a political environment where Democratic correlates with urban and Republican correlates with rural, this natural clumping can have an impact on proportional-political-representation.  In the appendix I discuss some measures of clumping that I analyzed, and others that I will look at further.  For this version of my analysis though, I have not included clumping as a predictor in my model fitting, and fully realize that any model that doesn’t include clumping is incomplete.  I will include clumping as I continue to refine my model.

The other predictor variable that I did include in my model fitting, aside from who did the redistricting, is the number of districts in the state.  Clearly if there are only 2 congressional seats, proportional-political-representation is unlikely.  And at the other end of the spectrum as an example are the 61 seats the Democratically controlled legislature in California had to work with when they drew district boundaries in 2001 – a number that gives numerous opportunities for cracking and packing.

## METHODS
In building the data frames for my analysis I’ve worked from: 1) election results from the Harvard Dataverse website, 2) An analysis done by the Brennan Center for Justice of who was responsible for redistricting in each state, and 3) population and land area data for 2000 and 2010, downloaded from Census.gov.

Aside from some data cleaning and data frame joining, the major data wrangling issue that I dealt with was imputing vote numbers for candidates who ran unopposed.  The vote tallies for unopposed candidates are not reflective of the number of Democratic and Republican voters in a district.  In it’s extreme, there are Florida’s vote records where the winning candidate is noted as having 1 vote.  Since my outcome measure was comparing % of seats (an accurate number) I needed a method get a more accurate total of votes within a state.

For each unopposed election, I calculated the maximum number of votes received by candidates of that party in the other districts in that state and then assigned that maximum vote total to the unopposed candidate.  And for the party that didn’t field a candidate, I created a candidate named “Imputed” and assigned them the minimum vote total from the other candidates of that party.  (When I do my analysis using the “efficiency gap” and wasted votes, I will revisit this method of imputing uncontested elections.)

Finally, for each county within each state I calculated the population density for each year.  Those values were used in my attempt to build a “clumping” metric (see the appendix).

When done, I had a data.frame for both Democratic results and Republican results.  And I did my data analysis from the Democra’s perspective and using the Democratic Results data frame.

```{r echo=FALSE, warning=FALSE, message=FALSE}
## (1) Load, clean and impute election data
### (1A) build "rslts" data.frame

#wget("https://dataverse.harvard.edu/api/access/datafile/:persistentId?persistentId=doi:10.7910/DVN/IG0UN2/ELBYL3")
rslts <- read.table("ELBYL3", header = TRUE)

# Historical note.  In the data file, there was a column "special."  There were two sets of elections where special="TRUE."  Both is Texas.  One in 1996, the other 2006.  In the first the US District Court found that the redrawn districts were unconstitutional and ordered a special election to redo the primary election - then held a general election in December.  And again in 2006, the US Supreme Court found that numerous redrawn districts were unconstitutional and again ordered a new district map and a special election for the primaries with a December general election.  Since these special elections were "redoing" the primary elections in those districts, I've removed them from the data set, thus keeping only the general elections in the data set.  These were the only cases in the data file where there where special elections.  And because of this story of split aliegance of who was doing the redistricting, I've put TX in the "Other" group for 2000 redistricting.
rslts <- filter(rslts, special = TRUE)

# From the data set, I've kept seven columns for my analysis and filtered out for years 2002 and beyond
# Originally I collected data for 1992 and beyond, but decided to use a smaller data set.  There is data cleaning built into the following code that is based on using years >= 1992.
rslts <-
  subset(
    rslts,
    select = c(
      year,
      state_po,
      district,
      candidate,
      party,
      candidatevotes,
      totalvotes
    )
  )
rslts <- rslts %>%  rename(state = state_po)
rslts <- filter(rslts, year >= 2002)
rslts$percent <- round(100 * rslts$candidatevotes / rslts$totalvotes, 2)

# NOTE: in Minnesota, the democratic party is called "democratic-farmer-labor," so I've changed it's name in the data.frame to "democrat."  And same for the republican party "independent-republican"
rslts$party[rslts$party == "democratic-farmer-labor"] <- "democrat"
rslts$party[rslts$party == "independent-republican"] <- "republican"

# Remove all states that only have one representative to congress - in these states there is never a need for redistricting (WY, VT, SD, ND, MT, DE, AK)
rslts <- filter(rslts, !state %in% c("WY", "VT", "SD", "ND", "MT", "DE", "AK"))

# Include candidates who are either republican or democrat
rslts <- filter(rslts, party == "democrat" | party == "republican")
```

```{r echo=FALSE}
### (1B) build "who" data.frma (the grouping variable)

#This code builds the "who" data.frame which will get joined with the election results data.frame (DemYearlyResults and RepubYearlyResults)
##Note to self: To keep my code consistent with my write-up, I should change "ind" and "I" to "other" and "O."
state_abbrs <- read.csv("states.csv")

state_abbrs_all <- filter(state_abbrs, !Code=="DC")
one_district <- c("WY", "VT", "SD", "ND", "MT", "DE", "AK")
state_abbrs <- filter(state_abbrs, !Code %in% c(one_district, "DC"))


repub_2010 <- c("AL", "FL", "GA", "IN", "LA", "MI", "NE", "NH", "NC", "OH", "OK", "PA", "SC", "TN", "UT", "VA", "WI")
dem_2010 <- c("AR", "IL", "MD", "MA", "RI", "WV")
ind_2010 <- c("AZ", "CA", "ID", "IA", "WA", "CO", "CT", "KS", "MN", "MS", "NV", "NM", "NY", "HI", "NJ", "KY", "ME", "MO", "OR", "TX")
repub_2000 <- c("FL", "IL", "KS", "MI", "NE", "OH", "PA", "UT", "VA")
dem_2000 <- c("AL", "CA", "GA", "IN", "MA", "MD", "NC", "WV")
ind_2000 <- c("AR", "AZ", "CO", "CT", "HI", "IA", "ID", "KY", "LA", "ME", "MN", "MO", "MS", "NH", "NJ", "NM", "NV", "NY", "OK", "OR", "RI", "SC", "TN", "TX", "WA", "WI")

who <- data.frame(year = integer(),
                         state = character(),
                         who = character())
for (i in seq(2002, 2010, 2)) {
  a <- data.frame(year = i,
                  state = repub_2000,
                  who = c("R"))
  b <- data.frame(year = i,
                  state = dem_2000,
                  who = c("D"))
  c <- data.frame(year = i,
                  state = ind_2000,
                  who = c("O"))
  who <- rbind(who, a, b, c)
}
who <- filter(who, !(state=="AR" & year == 2008))

for (i in seq(2012, 2018, 2)) {
  a <- data.frame(year = i,
                  state = repub_2010,
                  who = c("R"))
  b <- data.frame(year = i,
                  state = dem_2010,
                  who = c("D"))
  c <- data.frame(year = i,
                  state = ind_2010,
                  who = c("O"))
  who <- rbind(who, a, b, c)
}
who$who <- as.factor(who$who)
```

```{r echo=FALSE}
### (1C) Impute vote values for uncontested elections.
#### (1C-i) build uncontested and contested

#Initialize data.frames to collect data
uncontested <- data.frame(
  year = integer(),
  state = character(),
  district = integer(),
  candidate = character(),
  party = character(),
  candidatevotes = integer(),
  totalvotes = integer(),
  percent = numeric()
)

contested <- data.frame(
  year = integer(),
  state = character(),
  district = integer(),
  candidate = character(),
  party = character(),
  candidatevotes = integer(),
  totalvotes = integer(),
  percent = numeric()
)

YearlySummary <-
  data.frame(year = integer(),
             uncontested = integer(),
             competitive = integer())

#(A) For each year, for each state, for each district: collect up the districts where there was NOT both a Democrat and a Republican (uncontested), and the districts where there WAS both Dem & Repub (contested)

for (yr in seq(2002, 2018, 2)) {
  #count1 will count the number of uncontested races
  #count2 will count the number of competitive races
  count1 <- 0
  count2 <- 435
  for (st in state_abbrs$Code) {
    low <-
      min(rslts[rslts$year == yr & rslts$state == st,]$district)
    high <-
      max(rslts[rslts$year == yr & rslts$state == st,]$district)
    
    for (dst in seq(low, high)) {
      Dems <- (rslts[rslts$year == yr & rslts$state == st &
                       rslts$district == dst,]$party == "democrat")
      Repubs <- (rslts[rslts$year == yr & rslts$state == st &
                         rslts$district == dst,]$party == "republican")
      blowout <- (rslts[rslts$year == yr & rslts$state == st &
                          rslts$district == dst,]$percent > 55)
      if (sum(blowout, na.rm = TRUE) == 1) {
        count2 <- count2 - 1
      }
      
      if (sum(Dems, na.rm = TRUE) == 0 |
          sum(Repubs, na.rm = TRUE) == 0) {
        new <- rslts[rslts$year == yr & rslts$state == st &
                       rslts$district == dst,]
        count1 <- count1 + 1
        uncontested <- rbind(uncontested, new)
      } else {
        new <- rslts[rslts$year == yr & rslts$state == st &
                       rslts$district == dst,]
        contested <- rbind(contested, new)
      }
    }
  }
  
  new <-
    data.frame(year = yr,
               uncontested = count1,
               competitive = count2)
  YearlySummary <- rbind(YearlySummary, new)
}
```

```{r echo=FALSE}
#### (1C-ii) build YearlyVoteTotals and YearlyNoContesteds

#Initialize data.frames to collect data
YearlyVoteTotals <-
  data.frame(
    year = integer(),
    state = character(),
    party = character(),
    max = integer(),
    min = integer(),
    mean = integer(),
    adjusted_sum = integer(),
    adjusted_percent = numeric()
  )

YearlyNoContesteds <-
  data.frame(
    year = integer(),
    state = character(),
    num_districts = integer()
  )

#(B) Going year by year, state by state, find max and min votes for each party and store in a data.frame (which will be used to impute missing values)

for (yr in seq(2002, 2018, 2)) {
  for (st in state_abbrs$Code) {
    low <-
      min(rslts[rslts$year == yr & rslts$state == st,]$district)
    high <-
      max(rslts[rslts$year == yr & rslts$state == st,]$district)
    demvotes <- c()
    repubvotes <- c()
    
    #Just looking for max and min in the contested elections
    ContestedDistricts <- unique(contested[contested$year == yr &
                                             contested$state == st, ]$district)
    for (dst in ContestedDistricts) {
      demvotes <-
        append(demvotes, contested[contested$year == yr &
                                     contested$state == st &
                                     contested$district == dst &
                                     contested$party == "democrat", ]$candidatevotes)
      repubvotes <-
        append(repubvotes, contested[contested$year == yr &
                                       contested$state == st &
                                       contested$district == dst &
                                       contested$party == "republican", ]$candidatevotes)
    }
    if (length(ContestedDistricts)==0) {
      Districts <- unique(rslts[rslts$year == yr &
                                             rslts$state == st, ]$district)
      TotalDistricts <- max(Districts)-min(Districts)+1
      new <-
        data.frame(year = yr,
                   state = st,
                   num_districts = TotalDistricts
                   )
      YearlyNoContesteds <- rbind(YearlyNoContesteds, new)
      
    } else {
      newDem <-
        data.frame(
          year = yr,
          state = st,
          party = "democrat",
          max = max(demvotes),
          min = min(demvotes),
          adjusted_sum = 0,
          adjusted_percent = 0
        )
      newRepub <-
        data.frame(
          year = yr,
          state = st,
          party = "republican",
          max = max(repubvotes),
          min = min(repubvotes),
          adjusted_sum = 0,
          adjusted_percent = 0
        )
      YearlyVoteTotals <- rbind(YearlyVoteTotals, newDem, newRepub)
    }
  }
}
```

```{r echo=FALSE}
#### (1C-iii) build "imputed" data.frame

#NOTE: As the YearlyNoContesteds data.frame shows, there were two times where the whole states delegation was uncontested (1994 in "LA" and 2008 in "AR").  Since there is no data to impute from for each of these instances, I've removed them from both the "rslts" data.frame and the "uncontested" data.frame.
rslts <- filter(rslts, !(rslts$year == 1994 & rslts$state == "LA"))
rslts <- filter(rslts, !(rslts$year == 2008 & rslts$state == "AR"))
uncontested <- filter(uncontested, !(uncontested$year == 1994 & uncontested$state == "LA"))
uncontested <- filter(uncontested, !(uncontested$year == 2008 & uncontested$state == "AR"))

state_abbrs <- filter(state_abbrs, !Code %in% c("WY", "VT", "SD", "ND", "MT", "DE", "AK","DC"))
#Initialize data.frames to collect data
imputed <- data.frame(
  year = integer(),
  state = character(),
  district = integer(),
  candidate = character(),
  party = character(),
  candidatevotes = integer(),
  totalvotes = integer(),
  percent = numeric()
)

#(C) Create a data.frame of imputed "candidates" with their vote "totals" (minimum # of votes that party got in a district in that state for that election cycle)  And while doing this, replace rslts$candidatevotes with the imputed vote "total" for the uncontested candidate (maximum # of votes that party got in a district for that election cycle).

for (i in (1:nrow(uncontested))) {
  yr <- uncontested$year[i]
  st <- uncontested$state[i]
  dst <- uncontested$district[i]
  if (uncontested$party[i] == "democrat") {
    new_party <- "republican"
    new_votes_loser <-
      (YearlyVoteTotals[YearlyVoteTotals$year == yr &
                          YearlyVoteTotals$state == st &
                          YearlyVoteTotals$party == "republican",]$min)
    new_votes_winner <-
      (YearlyVoteTotals[YearlyVoteTotals$year == yr &
                          YearlyVoteTotals$state == st &
                          YearlyVoteTotals$party == "republican",]$max)
  } else {
    new_party <-  "democrat"
    new_votes_loser <-
      (YearlyVoteTotals[YearlyVoteTotals$year == yr &
                          YearlyVoteTotals$state == st &
                          YearlyVoteTotals$party == "democrat",]$min)
    new_votes_winner <-
      (YearlyVoteTotals[YearlyVoteTotals$year == yr &
                          YearlyVoteTotals$state == st &
                          YearlyVoteTotals$party == "democrat",]$max)
  }
  new_votes_total <- new_votes_loser + new_votes_winner
  
  new <- data.frame(
    year = uncontested$year[i],
    state = uncontested$state[i],
    district = uncontested$district[i],
    candidate = "imputed",
    party = new_party,
    candidatevotes = new_votes_loser,
    totalvotes = new_votes_total,
    percent = round(100 * new_votes_loser / new_votes_total, 2)
  )
  
  imputed <- rbind(imputed, new)
  
  #replace the votes and vote total for the uncontested candidate
  rw <-
    which(uncontested$year == yr &
            uncontested$state == st & uncontested$district == dst)
  uncontested$candidatevotes[rw] <- new_votes_winner
  uncontested$totalvotes[rw] <- new_votes_total
  uncontested$percent[rw] <-
    round(100 * new_votes_winner / new_votes_total, 2)
  
}

```

```{r echo=FALSE}
### (1D) build "density" data.frame

#wget("https://www2.census.gov/programs-surveys/popest/datasets/2000-2009/counties/totals/co-est2009-alldata.csv")
#wget("https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/counties/totals/co-est2019-alldata.csv")
#wget("https://www2.census.gov/prod2/statcomp/usac/excel/LND01.xls")
pop02_08 <- read.csv("co-est2009-alldata.csv")
pop10_18 <- read.csv("co-est2019-alldata.csv")
area <- readxl::read_excel("LND01.xls")

pop02_08 <- filter(pop02_08, STNAME != "District of Columbia")
pop10_18 <- filter(pop10_18, STNAME != "District of Columbia")
area <- filter(area, Areaname != c("UNITED STATES", "DISTRICT OF COLUMBIA", "District of Columbia"))

#create a STCOU column that matches the STCOU column in the area data.frame
#so I can eventually merge pop and area (to get density)
pop02_08$STCOU = 0
for (i in 1:nrow(pop02_08)) {
  pop02_08$STCOU[i] <- 1000 * pop02_08$STATE[i] + pop02_08$COUNTY[i]
}

pop10_18$STCOU = 0
for (i in 1:nrow(pop10_18)) {
  pop10_18$STCOU[i] <- 1000 * pop10_18$STATE[i] + pop10_18$COUNTY[i]
}

pop02_08 <- subset(
  pop02_08,
  select = c(
    STNAME,
    CTYNAME,
    STCOU,
    POPESTIMATE2002,
    POPESTIMATE2004,
    POPESTIMATE2006,
    POPESTIMATE2008
  )
)
pop10_18 <- subset(
  pop10_18,
  select = c(
    STNAME,
    CTYNAME,
    STCOU,
    POPESTIMATE2010,
    POPESTIMATE2012,
    POPESTIMATE2014,
    POPESTIMATE2016,
    POPESTIMATE2018
  )
)
area <- subset(
  area,
  select = c(
    Areaname,
    STCOU,
    LND010200D,
    LND110210D
  )
)
area <- area %>% rename(AREA_2000 = LND010200D, AREA_2010 = LND110210D)
area$STCOU <- as.numeric(area$STCOU)

#checking to see which counties don't match up
b <- unique(pop02_08$STCOU)
c <- unique(pop10_18$STCOU)
'%notin%' <- Negate("%in%")
dropped_from_02_08 <- pop02_08[which(b %notin% c),]
added_in_10_18 <- pop10_18[which(c %notin% b),]

#cleaning up the two instances, prior to joining, where counties were given "different name" (e.g. "La Salle" vs. "LaSalle")
pop10_18[pop10_18$STCOU==2195,]$CTYNAME <- "Petersburg Census Area"
pop02_08[pop02_08$STCOU==22059,]$CTYNAME <- "LaSalle Parish"
pop <- full_join(pop02_08, pop10_18, by=c("STNAME", "CTYNAME", "STCOU"))

d <- unique(pop$STCOU)
in_pop_butnot_02_08 <- pop[which(d %notin% b),]
in_pop_butnot_10_18 <- pop[which(d %notin% c),]


#checking to see which counties don't match up
a <- unique(area$STCOU)
p <- unique(pop$STCOU)
a_notin_p <- area[which(a %notin% p),]
p_notin_a <- pop[which(p %notin% a),]


dnsty <- left_join(pop, area, by="STCOU")
dnsty <- subset(dnsty, select=-Areaname)

#Because  neither Kuslivak Census Area in AK, nor Oglala Lakota County in SD (or three others) had records in the area data file, I googled the land area for each of these counties and am manually entering them in to the density data.frame.
dnsty[dnsty$STCOU==2158,]$AREA_2010 <- 17081
dnsty[dnsty$STCOU==46102,]$AREA_2010 <- 2094
dnsty[dnsty$STCOU==2230,]$AREA_2000 <- 452
dnsty[dnsty$STCOU==2275,]$AREA_2000 <- 2556
dnsty[dnsty$STCOU==8014,]$AREA_2000 <- 33

#calculating population density for each year (YEAH - I should be able to do this in a loop, instead of the over-and-over code I've used below - but I'm being lazy).
dnsty$DENSITY2002 <- round(dnsty$POPESTIMATE2002/dnsty$AREA_2000, 2)
dnsty$DENSITY2004 <- round(dnsty$POPESTIMATE2004/dnsty$AREA_2000, 2)
dnsty$DENSITY2006 <- round(dnsty$POPESTIMATE2006/dnsty$AREA_2000, 2)
dnsty$DENSITY2008 <- round(dnsty$POPESTIMATE2008/dnsty$AREA_2000, 2)
dnsty$DENSITY2010 <- round(dnsty$POPESTIMATE2010/dnsty$AREA_2010, 2)
dnsty$DENSITY2012 <- round(dnsty$POPESTIMATE2012/dnsty$AREA_2010, 2)
dnsty$DENSITY2014 <- round(dnsty$POPESTIMATE2014/dnsty$AREA_2010, 2)
dnsty$DENSITY2016 <- round(dnsty$POPESTIMATE2016/dnsty$AREA_2010, 2)
dnsty$DENSITY2018 <- round(dnsty$POPESTIMATE2018/dnsty$AREA_2010, 2)

#removing state level data and leaving just county data
dnsty_states <- filter(dnsty, dnsty$STNAME==dnsty$CTYNAME)
dnsty <- filter(dnsty, !dnsty$STNAME==dnsty$CTYNAME)

```

```{r echo=FALSE}
### (1E) build "clumping" data.frame

#Calculating yearly density IQR by state as a measure of clumping
clumping1 <- dnsty %>% 
  group_by(STNAME) %>% 
  summarise("2002" = IQR(DENSITY2002, na.rm=TRUE),
            "2004" = IQR(DENSITY2004, na.rm=TRUE),
            "2006" = IQR(DENSITY2006, na.rm=TRUE),
            "2008" = IQR(DENSITY2008, na.rm=TRUE),
            "2010" = IQR(DENSITY2010, na.rm=TRUE),
            "2012" = IQR(DENSITY2012, na.rm=TRUE),
            "2014" = IQR(DENSITY2014, na.rm=TRUE),
            "2016" = IQR(DENSITY2016, na.rm=TRUE),
            "2018" = IQR(DENSITY2018, na.rm=TRUE)
  )
clumping1 <- clumping1 %>%  rename(State = STNAME)
clumping1 <- inner_join(clumping1, state_abbrs_all, by="State")
clumping1 <- select(clumping1, -c('State', 'Abbrev'))
clumping1 <- clumping1 %>%  rename(state = Code)
clumping1 <- clumping1 %>% pivot_longer(!state, names_to="year", values_to="density_IQR")
clumping1 <- filter(clumping1, (clumping1$state %notin% one_district))
clumping1 <- filter(clumping1, !(clumping1$year == 1994 & clumping1$state == "LA"))
clumping1 <- filter(clumping1, !(clumping1$year == 2008 & clumping1$state == "AR"))
clumping1$year <- as.numeric(clumping1$year)

#Calculating yearly density stDev by state as a measure of clumping
clumping2 <- dnsty %>% 
  group_by(STNAME) %>% 
  summarise("2002" = sd(DENSITY2002, na.rm=TRUE),
            "2004" = sd(DENSITY2004, na.rm=TRUE),
            "2006" = sd(DENSITY2006, na.rm=TRUE),
            "2008" = sd(DENSITY2008, na.rm=TRUE),
            "2010" = sd(DENSITY2010, na.rm=TRUE),
            "2012" = sd(DENSITY2012, na.rm=TRUE),
            "2014" = sd(DENSITY2014, na.rm=TRUE),
            "2016" = sd(DENSITY2016, na.rm=TRUE),
            "2018" = sd(DENSITY2018, na.rm=TRUE)
  )
clumping2 <- clumping2 %>%  rename(State = STNAME)
clumping2 <- inner_join(clumping2, state_abbrs_all, by="State")
clumping2 <- select(clumping2, -c('State', 'Abbrev'))
clumping2 <- clumping2 %>%  rename(state = Code)
clumping2 <- clumping2 %>% pivot_longer(!state, names_to="year", values_to="density_sd")
clumping2 <- filter(clumping2, (clumping2$state %notin% one_district))
clumping2 <- filter(clumping2, !(clumping2$year == 1994 & clumping2$state == "LA"))
clumping2 <- filter(clumping2, !(clumping2$year == 2008 & clumping2$state == "AR"))
clumping2$year <- as.numeric(clumping2$year)

#Hope to build a clumping3 variable that would use the Census' Urban centers as a way to measure the amount of clumping within a state
#clumping3 <-
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.pos="H"}

### (1F) put it all together into Results and DemYearlyResults & RepubYearlyResults

Results <- rbind(contested, uncontested, imputed)
Results$winner <- c("?")

#by year by state get the winner for each district
for (yr in seq(2002, 2018, 2)) {
  for (st in state_abbrs$Code) {
    if ((st == "LA" & yr == 1994) | (st == "AR" & yr == 2008)) {
      #skip the dst loop for the two years/states when there were no contested elections
    } else {
      Districts <- unique(Results[Results$year == yr &
                                    Results$state == st, ]$district)
      for (dst in (min(Districts):max(Districts))) {
        if (Results[Results$year == yr &
                    Results$state == st &
                    Results$district == dst &
                    Results$party == "democrat",]$candidatevotes >
            Results[Results$year == yr &
                    Results$state == st &
                    Results$district == dst &
                    Results$party == "republican",]$candidatevotes) {
          Results[Results$year == yr &
                    Results$state == st &
                    Results$district == dst &
                    Results$party == "democrat",]$winner <- "won"
          Results[Results$year == yr &
                    Results$state == st &
                    Results$district == dst &
                    Results$party == "republican",]$winner <-
            "lost"
        } else {
          Results[Results$year == yr &
                    Results$state == st &
                    Results$district == dst &
                    Results$party == "republican",]$winner <- "won"
          Results[Results$year == yr &
                    Results$state == st &
                    Results$district == dst &
                    Results$party == "democrat",]$winner <- "lost"
        }
      }
    }
  }
}

#calculate the total votes and total seats
YearlyResults <- Results %>%
  group_by(year, state, party) %>%
  summarise(votes = sum(candidatevotes))
YearlyResults <- ungroup(YearlyResults)

YearlyResults$vote_percentage <- seq(0, 1, nrow(YearlyResults))
YearlyResults$seats <- seq(0, 1, nrow(YearlyResults))
YearlyResults$seat_percentage <- seq(0, 1, nrow(YearlyResults))

for (yr in seq(2002, 2018, 2)) {
  for (st in state_abbrs$Code) {
    demvotes <- YearlyResults[YearlyResults$year == yr &
                                YearlyResults$state == st &
                                YearlyResults$party == "democrat", ]$votes
    
    repubvotes <- YearlyResults[YearlyResults$year == yr &
                                  YearlyResults$state == st &
                                  YearlyResults$party == "republican", ]$votes
    
    totalvotes <- demvotes + repubvotes
    
    YearlyResults[YearlyResults$year == yr &
                    YearlyResults$state == st &
                    YearlyResults$party == "democrat",]$vote_percentage <-
      round(100 * demvotes / totalvotes, 2)
    YearlyResults[YearlyResults$year == yr &
                    YearlyResults$state == st &
                    YearlyResults$party == "republican",]$vote_percentage <-
      round(100 * repubvotes / totalvotes, 2)
    
    demseats <-
      nrow(Results[Results$year == yr &
                     Results$state == st &
                     Results$party == "democrat" &
                     Results$winner == "won",])
    repubseats <-
      nrow(Results[Results$year == yr &
                     Results$state == st &
                     Results$party == "republican" &
                     Results$winner == "won",])
    totalseats <- demseats + repubseats
    
    YearlyResults[YearlyResults$year == yr &
                    YearlyResults$state == st &
                    YearlyResults$party == "democrat",]$seat_percentage <-
      round(100 * demseats / totalseats, 2)
    YearlyResults[YearlyResults$year == yr &
                    YearlyResults$state == st &
                    YearlyResults$party == "republican",]$seat_percentage <-
      round(100 * repubseats / totalseats, 2)
    YearlyResults[YearlyResults$year == yr &
                    YearlyResults$state == st,]$seats <-
      totalseats
  }
}

DemYearlyResults <- filter(YearlyResults, party=="democrat")
DemYearlyResults <- DemYearlyResults %>% inner_join(who, by = c("year", "state"))
DemYearlyResults$ppr <- round(DemYearlyResults$seat_percentage/DemYearlyResults$vote_percentage, 2) 
DemYearlyResults <- inner_join(DemYearlyResults, clumping1, c("year", "state"))
DemYearlyResults <- inner_join(DemYearlyResults, clumping2, c("year", "state"))
RepubYearlyResults <- filter(YearlyResults, party=="republican")
RepubYearlyResults <- RepubYearlyResults %>% inner_join(who, by = c("year", "state"))
RepubYearlyResults$ppr <- round(RepubYearlyResults$seat_percentage/RepubYearlyResults$vote_percentage, 2) 
RepubYearlyResults <- inner_join(RepubYearlyResults, clumping1, c("year", "state"))
RepubYearlyResults <- inner_join(RepubYearlyResults, clumping2, c("year", "state"))

kable(head(subset(DemYearlyResults, select=c(year, state, party, seats, who, ppr)),
           5), align="lllccc", digits=2)
```

## EDA
##### what's the distribution of PPR look like
Visually the distribution of PPR looks normal, which the exception of the 35 elections where the Democrats won zero of the congressional seats in that state (regardless of their vote percentage).  And when subset the PPR's by quantile, it's clear that with more congretional seats, the results are less varied and move toward a mean PPR of 1 (a politically proportional result).  Finally a Q-Qplot of PPR (and log(PPR)) and a Shapiro-Wilk normality test (p=.00001) show that PPR is normally distributed (noting the exception of the 35 PPR results).  Given this, I am assuming normality of my outcome variable for my regression fitting, and am using PPR instead of log(PPR).
```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.pos="H", out.width="50%"}
ggplot(DemYearlyResults, aes(ppr, color=who)) +
  geom_histogram(binwidth = .1, fill="cornflowerblue", size=1)  +
  scale_color_manual(name="who redistricted?", values = c("blue", "green", "red"),
                     labels= c("Democrats", "Other", "Republicans")) +
  labs(title="Distribution of ppr for Democrats") +
  theme_bw()

PlotDems <- DemYearlyResults
PlotDems$number_of_seats <- Hmisc::cut2(PlotDems$seats, g=5)
ggplot(PlotDems, aes(x=ppr, fill=number_of_seats)) +
  geom_histogram(binwidth = .1)  +
  labs(title="Distribution of ppr for Democrats") +
  scale_color_manual(name="who redistricted?", values = c("blue", "green", "red"),
                     labels= c("Democrats", "Other", "Republicans")) +
  scale_y_continuous(NULL, breaks=NULL) +
  theme_bw()
```


```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.pos="H", out.width="50%"}
ggqqplot(DemYearlyResults$ppr) + labs(title="Q-Qplot of ppr")
ggqqplot(log(DemYearlyResults$ppr+1)) + labs(title="Q-Qplot of log(ppr)")

#shapiro.test(DemYearlyResults$ppr)
#shapiro.test(log(DemYearlyResults$ppr+1))
```

##### who vs. PPR (seat/vote)
Just looking at the comparison between the three groups who redistricted, it's visually clear that the democrats were advantaged when Democratic controlled states redistricted, and Democrats where disadvantaged when Republican controlled states redistricted.  But we already knew this was true.


```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height=4, fig.show="hold"}

ggplot(DemYearlyResults, aes(y=ppr, x=who, color=who)) +
  labs(y="PPR (1 = proportionally fair)", 
       caption="Note: each point represents a state in a given year",
       title="PPR (prop_seats / prop_vote) for DEMOCRATS") +
  geom_violin(size=1, fill="cornflowerblue") +
  scale_color_manual(name="who redistricted?", values = c("blue", "green", "red"),
                     labels= c("Democrats", "Other", "Republicans")) +
  geom_abline(slope=0, intercept=1, color = "black", ) +
  geom_dotplot(binaxis="y", stackdir="center", dotsize = .5, color="cornflowerblue", binwidth = .05) +
  theme(axis.title.x=element_blank(), axis.ticks.x=element_blank(), axis.text.x=element_blank())

```


##### size of district vs. political proportionality (seat/vote)
In looking at the relationship between the size of the district and PPR, there is no visual pattern in the aggregate.  And the grouped pattern is as expected when the redistricting was not done by either Democrats or Republicans: the size of the seat doesn't appear to influence the "fairness."  But when looking at Democratly controlled redistricting it appears that more seats there are to redistrict the more likely the results advantage the Democrats.  Whereas with Republican controlled redistricting, the opposite appears true. 

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.pos="H", out.width="50%"}
ggplot(DemYearlyResults, aes(log(seats), ppr)) +
  geom_point() + geom_smooth(method=lm) +
  geom_abline(slope = 0,
              intercept = 1,
              color = "grey") +
  theme_bw()

ggplot(DemYearlyResults, aes(log(seats), ppr, color=who))+
  geom_point() + geom_smooth(method=lm, se=FALSE) +
  scale_color_manual(name="who redistricted?", values = c("blue", "green", "red"),
                     labels= c("Democrats", "Other", "Republicans")) +
  geom_abline(slope = 0,
              intercept = 1,
              color = "grey") +
  theme_bw()
```


This is what it looks like with just the politically redistricted states over the years 2002 to 2018.  I've removed all states where some other entity aside from Democratic or Republican controlled legislatures, did the redistricting.

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.height=4, fig.pos="H"}

ggplot(DemYearlyResults[DemYearlyResults$who != "O",], aes(log(seats), ppr)) +
  geom_point() + geom_smooth(method=lm) +
  geom_abline(slope = 0,
              intercept = 1,
              color = "grey") +
  #geom_text(aes(label=state), size = 2, hjust=-0.5, vjust=-.5) +
  theme_bw()

fit <- lm(ppr~log(seats), DemYearlyResults[DemYearlyResults$who != "O",])
```


```{r echo=FALSE, fig.pos="H"}
pander(summary(fit))
```

## Model fitting
```{r echo=FALSE, warning=FALSE, message=FALSE, fig.height=4}
ggplot(DemYearlyResults, aes(log(seats), ppr, color=who))+
  geom_point() + geom_smooth(method=lm, se=FALSE) +
  scale_color_manual(name="who redistricted?", values = c("blue", "green", "red"),
                     labels= c("Democrats", "Other", "Republicans")) +
  geom_abline(slope = 0,
              intercept = 1,
              color = "grey") +
  #geom_text(aes(label=state), size = 2, hjust=-0.5, vjust=-.5) +
  theme_bw()

fit1 <- lmer(ppr ~ (log(seats)|who) -1, data=DemYearlyResults)
#summary(fit1)

fit2 <- lmer(ppr ~ log(seats) + (1+seats|who), data=DemYearlyResults)
#summary(fit2)

fit3 <- lm(ppr ~ who + who:log(seats) + 0, data=DemYearlyResults)
#summary(fit3)

fit4 <- lm(ppr ~ who, data = DemYearlyResults)
#summary(fit4)
```

## RESULTS

## DISCUSSION

## BIBLIOGRAPHY and APPENDIX
### Metrics
### (I) Who to include?
In looking at vote results I had to decide which parties to include.  As such combined Minnesota's "democratic-farmer-labor" party with the democrat party.  I looked at the entirety of listed parties, to see what parties aside from the democrats and the republicans where significant either in the number of candidates or the votes.  The only party that was worthy of consideration aside from the two major parties was the Libertarian party.
The Libertarians ran candidates in 2,018 elections between 1990 and 2018.  But never got higher than 31% of the vote and their mean vote percentage was 3.4% (with a distribution of results that was heavily skewed right with "skewness" = 3.4).  As such I have not included the "libertarian" party as a major party, and have confined my analysis to Democrats and Republicans.
```{r echo=FALSE, warning=FALSE, message=FALSE}

libs <- filter(rslts, party == "libertarian")
num_libertarian_canditates <- nrow(libs)
high_percent_libertarians <- max(libs$percent)
mean_percent_libertarians <- mean(libs$percent)
skew_percent_libertarians <- skewness(libs$percent)
```

### (II) Is it politically fair?
#### (IIa)vote_percentage vs seat_percentage
Originally, I looked at representing "politically fair" where the outcome variable was the proportion of house seats won and the predictor was the proportion of votes won.  If an election was fair then these two proportions would be equal.  State-years where the vote_proportion and the seat_proportion fell on the y=x line (grey line in the graphs), were proportionally equal/fair.  Additionally I used color to note who did the redistricting and how many seats were decided (with the notion that for a state with a small number of seats, it would not be surprising to have a big difference in vote and seat proportions, e.g. NH-2016 democrats had 46% of the vote but 0% of the two congressional seats).
Ultimately I decided that this representation was harder to visualize.  And the clumping variable was not a predictor variable for the proportion of seats won, but rather a possible predictor variable for political proportionality.  As such I decided to center my analysis around a measure of political fairness (seat_proportion / vote_proportion).  
```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.show="hold", out.width="33%"}

ggplot(DemYearlyResults[DemYearlyResults$who==c("D", "R"), ]) +
  aes(x = vote_percentage, y = seat_percentage, color = who) +
  scale_color_manual(values = c("blue", "red")) +
  geom_point(aes(size = seats, color=who),
             alpha = 0.5) +
  labs(x = "% of votes that were Democratic", y = "% of seats that are Democratic", title = "Proportional Representation?", subtitle = "Democratic vs. Rebulican controlled redistricting on Democratic results", col = "who redistricted", size = "number of seats") +
  geom_abline(slope = 1,
              intercept = 0,
              color = "grey") +
  xlim(20, 80) + ylim(0,100) +
  theme_bw()

ggplot(RepubYearlyResults[RepubYearlyResults$who==c("D", "R"), ]) +
  aes(x = vote_percentage, y = seat_percentage, color = who) +
  scale_color_manual(values = c("blue", "red")) +
  geom_point(aes(size = seats, color=who),
             alpha = 0.5) +
  labs(x = "% of votes that were Republican", y = "% of seats that are Republican", title = "Proportional Representation?", subtitle = "Democratic vs. Rebulican controlled redistricting on Republican results", col = "who redistricted", size = "number of seats") +
  geom_abline(slope = 1,
              intercept = 0,
              color = "grey") +
  xlim(20, 80) + ylim(0,100) +
  theme_bw()

ggplot(DemYearlyResults) +
  aes(x = vote_percentage, y = seat_percentage, color = who) +
  scale_color_manual(values = c("blue", "green", "red")) +
  geom_point(aes(size = seats, color=who),
             alpha = 0.5) +
  labs(x = "% of votes that were Democratic", y = "% of seats that are Democratic", title = "Proportional Representation?", subtitle = "Democratic vs. Rebulican vs. Other controlled redistricting on Democratic results", col = "who redistricted", size = "number of seats") +
  geom_abline(slope = 1,
              intercept = 0,
              color = "grey") +
  geom_smooth(method=lm, se=FALSE) +
  xlim(20, 80) + ylim(0,100) +
  theme_bw()

```

#### (IIb) The efficiency gap & wasted votes  
When "cracking" or "packing," voters are moved into or out of districts to dilute the power of their vote.  The efficiency gap is a mathematical calculation that "counts the number of votes each party wastes in an election to determine whether either party enoyed a systematic advantice in turning votes into seats." ("How the Efficiency Gap Works," Petry, 2015, http://bettergov.nc.lwvnet.org/files/how_the_efficiency_gap_standard_works.pdf).  I have not yet taken the time to write the code to calculate the efficiency gap and then explore how illustrative it is as a measure of political fairness.

### (III) How to measure clumping.
I'm still trying to wrap my head around how to appropriately measure "clumping" so that the measurement will have meaning in the context of packing and cracking.

#### (IIIa) looking at the distribution of county densities, to help structure a "clumping" metric
```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.show="hold", out.width="33%"}

StateInfo1 <- dnsty %>%
  group_by(STNAME) %>%
  summarise(num_counties = n())
StateInfo1 <- StateInfo1 %>% rename(State = STNAME)
StateInfo2a <- rslts %>%
  group_by(state) %>%
  summarise(num_districts = n_distinct(district))
StateInfo2b <- data.frame(
  state=one_district,
  num_districts = c(1)
)
StateInfo2 <- rbind(StateInfo2a, StateInfo2b)
StateInfo2 <- StateInfo2 %>% rename(Code = state) 
StateInfo2 <- inner_join(state_abbrs_all, StateInfo2, by="Code")
StateInfo <- inner_join(StateInfo1, StateInfo2, by="State")

ggplot(StateInfo, aes(y=num_counties, x=num_districts)) +
  geom_point(size = 0.1) +
  geom_text(aes(label=Code), size = 2, hjust=-0.5, vjust=-.5) +
  geom_abline(slope = 1, intercept = 0, color = "red") +
  labs(title="How do the number of counties compare to the number of states?")

ggplot(dnsty[dnsty$STNAME=="Massachusetts",], aes(x=DENSITY2002)) +
  geom_dotplot() +
  labs(title="What's the distribution of county density look like in MA?")

ggplot(dnsty, aes(x=DENSITY2002)) +
  geom_histogram(binwidth = 50) +
  xlim(0,1000) +
  labs(title="What's the distribution of county densities look like across the US?",
       x="County densities in people/square mile (with 114 counties > 1000/sq mi)",
       caption = "NOTE: an 'urban center' is a region > 1000/sq mi.  So these are all 'rural' counties")

#length(dnsty[dnsty$DENSITY2002 > 1000, ]$DENSITY2002)

```
#### (IIIa) IQR of county level population density
For each state, for each year, I've calculated the spread of county population densities
```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.show="hold", out.width="50%"}
ggplot(DemYearlyResults) +
  aes(x = density_IQR, y = ppr) +
  geom_point(aes(size = seats), alpha = 0.5) +
  geom_text(aes(label=state), size = 2, hjust=-0.5, vjust=-.5, check_overlap = TRUE) +
  geom_smooth(method=lm, se=FALSE) +
  xlim(0,250) +
  theme_bw()

ggplot(DemYearlyResults) +
  aes(x = density_IQR, y = ppr, color=who) +
  geom_point(aes(size = seats), alpha = 0.5) +
  geom_text(aes(label=state), size = 2, hjust=-0.5, vjust=-.5, check_overlap = TRUE) +
  geom_smooth(method=lm, se=FALSE) +
  xlim(0,250) +
  theme_bw()

#do a mean(density_) and mean(proportion) for each state, then label the states...  will help to see state patterns

fit <- lm(ppr ~ density_IQR, data=DemYearlyResults)

```

```{r echo=FALSE}
pander(summary(fit))
```

#### (IIIb) standard deviation of county level population density
For each state, for each year, I've calculated the spread of county population densities
```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.show="hold"}

ggplot(DemYearlyResults) +
  aes(x = density_sd, y = ppr) +
  geom_point(aes(size = seats), alpha = 0.5) +
  geom_text(aes(label=state), size = 2, hjust=-0.5, vjust=-.5) +
  geom_smooth(method=lm, se=FALSE) +
  theme_bw()
ggplot(DemYearlyResults) +
  aes(x = density_sd, y = ppr, color=who) +
  geom_point(aes(size = seats), alpha = 0.5) +
  geom_text(aes(label=state), size = 2, hjust=-0.5, vjust=-.5) +
  geom_smooth(method=lm, se=FALSE) +
  theme_bw()

#do a mean(density_) and mean(ppr) for each state, then label the states...  will help to see state patterns
```

#### (IIIc) comparing state level population density, with county level population density, with Census defined "Urban centers"
This will be my next clumping variable attempt.

### (IV) who is making the redistricting decisions
These are the sources I used to create the group variable "who" for each election decade (2002-2010 & 2012-2018).  The "who" variable attributes the responsibility for the redistricting to either D, R, or I (Democratically controlled state legislatures, Republican controlled state legislatures, or Other).  I've defined "Other" as not Democratically controlled nor Republican controlled.  "Other" includes court ordered redistricting, split-party redistricting, and non-political commissions.  

https://www.ncsl.org/documents/statevote/2010_Legis_and_State_post.pdf  
https://www.brennancenter.org/our-work/research-reports/redistricting-and-congressional-control-first-look  
https://www.brennancenter.org/sites/default/files/2019-08/Report_CGR-2010-edition.pdf  

### (V) looking for a pattern in the number of uncontested and competitive congretional races by year
Though there is a great deal that's been written about how political gerrymandering is increasing the number of uncontested elections, and decreasing the number of competitive elections, my analysis doesn't bear this out.  Though my quick look is looking at all elections and is not looking at the grouping variable of who is doing the redistricting.
```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.show="hold", out.width="33%"}

ggplot(YearlySummary) +
  aes(x = year, y = uncontested) +
  geom_point() +
  geom_smooth(method=lm) +
  theme_bw()
fit1 <- lm(uncontested ~ year, data=YearlySummary)

ggplot(YearlySummary) +
  aes(x = year, y = competitive) +
  geom_point() +
  geom_smooth(method=lm) +
  theme_bw()
fit2 <- lm(competitive ~ year, data=YearlySummary)
```


```{r echo=FALSE}
pander(summary(fit2))
pander(summary(fit1))
```

```{r echo=FALSE}
### An example data.frame to think through my model fitting

# States <- read_csv("States.csv")
# 
# edf12 <- data.frame(year = rep("2012", nrow(States)),
#                   state = States,
#                   clumping1 = round(abs(rnorm(nrow(States), 150, 200)), 1),
#                   group = rep(factor(c("Dem", "Rep", "Ind", "Split")), length.out=nrow(States)),
#                   votes = round(60 + rnorm(nrow(States), 0, 10), 1),
#                   seats = round(runif(nrow(States), 0, 100),1))
# edf14 <- data.frame(year = rep("2014", nrow(States)),
#                   state = States,
#                   clumping1 = round(abs(rnorm(nrow(States), 150, 200)), 1),
#                   group = rep(factor(c("Dem", "Rep", "Ind", "Split")), length.out=nrow(States)),
#                   votes = round(60 + rnorm(nrow(States), 0, 10), 1),
#                   seats = round(runif(nrow(States), 0, 100),1))
# edf <- rbind(edf12, edf14)

# ggplot(data=edf) +
#   geom_point(aes(x=votes, y=seats, color=group)) +
#   geom_smooth(method=lm, aes(x=votes, y=seats, color=group), se=FALSE)
# 
# 
# fit <- lmer(seats ~ votes + (1+votes|group), data=edf)
#  #unable to evaluate scaled gradientModel failed to converge: degenerate  Hessian with 1 negative eigenvalues
# 
#  fit <- lmer(seats ~ (1|group), data=edf)
#  coef(fit)
#  confint(fit)
# 
#  fit <- stan_lmer(seats ~ clumping1 + votes + (1+votes|group), control = list(adapt_delta = 0.99), data = edf)
#  summary(fit)
#  coef(fit)
#  posterior_interval(fit)
# 
#  pairs(fit)
```


```{r echo=FALSE}
### lmer() code for fitting to DemYearlyResults

# fit <- lmer(seat_percentage ~ vote_percentage + (1+vote_percentage|who), data=DemYearlyResults)
# #with edf: unable to evaluate scaled gradientModel failed to converge: degenerate  Hessian with 1 negative eigenvalues
# 
# fit <- lmer(seat_percentage ~ (1|who), data=DemYearlyResults)
# coef(fit)
# confint(fit)
# 
# fit <- lmer(seat_percentage ~ (vote_percentage|who), data=DemYearlyResults)
# coef(fit)
# 
# fit <- stan_lmer(seat_percentage ~ vote_percentage + (1+vote_percentage|who), control = list(adapt_delta = 0.99), data = DemYearlyResults)
# summary(fit)
# coef(fit)
# posterior_interval(fit)
# 
# pairs(fit)
```

## Citations 
(need to figure out how to use LaTex or ?? to display this citation)
@incollection{DVN/IG0UN2/ELBYL3_2017,
author = {MIT Election Data and Science Lab},
publisher = {Harvard Dataverse},
title = {1976-2018-house2.tab},
booktitle = {U.S. House 1976–2018},
UNF = {UNF:6:8iuXTceVO5a7EpOwUD5UPw==},
year = {2017},
version = {V7},
doi = {10.7910/DVN/IG0UN2/ELBYL3},
url = {https://doi.org/10.7910/DVN/IG0UN2/ELBYL3}
}

https://www.census.gov/library/publications/2011/compendia/usa-counties-2011.html#POP

to get .xls for population and .xls for area:

https://www.google.com/url?sa=t&rct=j&q=&esrc=s&source=web&cd=&ved=2ahUKEwjHkPmp4bftAhV5FlkFHbDHBvwQFjAAegQIAxAC&url=https%3A%2F%2Fwww2.census.gov%2Flibrary%2Fpublications%2F2011%2Fcompendia%2Fusa-counties%2Fexcel%2FMastdata.xls&usg=AOvVaw1ahgb3GWupqOb1UHYbZlMw


Copyright
Copyright 2020 Bruce C. Mallory

Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:

1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.

2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.

3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.